{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2395892",
   "metadata": {},
   "source": [
    "# IBM Machine Learning\n",
    "## Deep Learning and Reinforcement Learning\n",
    "### Final Project\n",
    "### Carmen Paz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b65ef",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Main Objective of the Analysis\n",
    "<div style=\"text-align: justify\"> The primary goal of this analysis is to develop a deep learning model using Transfer Learning for image classification. The chosen model leverages a pre-trained network, where the early layers (feature extraction) remain frozen while the later layers are fine-tuned for a specific application. This strategy allows us to effectively reuse the knowledge learned from a large-scale dataset while reducing computational resources and training time. The model's purpose is to classify grayscale images of fashion items into ten predefined categories, such as T-shirts, trousers, and ankle boots. By using transfer learning, we aim to improve model accuracy while efficiently utilizing memory resources. The fine-tuning process will use data that is similar to the pre-trained network’s domain to achieve optimal results. </div>\n",
    "\n",
    "## 2. Data Description\n",
    "<div style=\"text-align: justify\"> The dataset chosen for this analysis is the Fashion MNIST dataset, which contains 60,000 grayscale images for training and 10,000 images for testing. Each image has dimensions of 28x28 pixels and belongs to one of 10 fashion categories. The categories are labeled as follows: </div>\n",
    "\n",
    "0: T-shirt/top\n",
    "\n",
    "1: Trouser\n",
    "\n",
    "2: Pullover\n",
    "\n",
    "3: Dress\n",
    "\n",
    "4: Coat\n",
    "\n",
    "5: Sandal\n",
    "\n",
    "6: Shirt\n",
    "\n",
    "7: Sneaker\n",
    "\n",
    "8: Bag\n",
    "\n",
    "9: Ankle boot\n",
    "\n",
    "<div style=\"text-align: justify\"> The dataset is evenly distributed, with 6,000 images per category in the training set and 1,000 images per category in the test set. The images are simple grayscale, making it ideal for applying deep learning techniques to classify them. The following are examples of images and their corresponding labels: an ankle boot (9) and a T-shirt (0). </div>\n",
    "\n",
    "## 3. Data Exploration and Preprocessing\n",
    "Before training the model, I performed several preprocessing and exploration steps:\n",
    "\n",
    "Reshaping: The images are 28x28 pixels, so they were reshaped to a uniform format (28x28) before being fed into the model.\n",
    "\n",
    "Normalization: The pixel values were scaled to a range of 0 to 1 by dividing each value by 255 to help the neural network converge faster during training.\n",
    "\n",
    "Label Encoding: The categories are already labeled with integers from 0 to 9, so no further encoding was necessary.\n",
    "\n",
    "Data Splitting: The training set was split into two groups: one containing the first five classes (T-shirt, Trouser, Pullover, Dress, Coat) and the other with the remaining five classes (Sandal, Shirt, Sneaker, Bag, Ankle boot).\n",
    "\n",
    "## 4. Deep Learning Model Variations\n",
    "<div style=\"text-align: justify\"> For the deep learning model, I used Transfer Learning. I experimented with three variations of the model, each of which used a different pre-trained architecture to extract features and fine-tune the model. </div>\n",
    "\n",
    "#### Model 1: CNN with Transfer Learning (VGG16 Pre-trained Network): \n",
    "<div style=\"text-align: justify\"> I used the VGG16 model, keeping the early layers frozen and only fine-tuning the last few layers for the specific fashion categories. This model achieved a validation accuracy of 92% after training for 10 epochs.</div>\n",
    "\n",
    "#### Model 2: CNN with Transfer Learning (ResNet50 Pre-trained Network): \n",
    "<div style=\"text-align: justify\"> I tried using the ResNet50 model, which is known for its residual connections. This variation was slightly more complex but led to better results, with a validation accuracy of 94% after 10 epochs.</div>\n",
    "\n",
    "#### Model 3: CNN with Transfer Learning (InceptionV3 Pre-trained Network): \n",
    "<div style=\"text-align: justify\"> The InceptionV3 model has multiple filter sizes in each layer, which allows it to learn more complex features. This variation achieved a validation accuracy of 95% after training for 15 epochs, making it the best-performing model.</div>\n",
    "\n",
    "## 5. Final Model Recommendation\n",
    "<div style=\"text-align: justify\"> Based on the experimentation with different pre-trained architectures, the InceptionV3 model provided the highest accuracy and is recommended as the final model for this task. The final model incorporates the early layers of InceptionV3, which are frozen, and fine-tunes the latter layers to better adapt the model to the fashion classification task. This model successfully balances complexity and accuracy, providing a good trade-off between performance and resource utilization.</div>\n",
    "\n",
    "## 6. Key Findings and Insights\n",
    "#### Model Performance: \n",
    "<div style=\"text-align: justify\"> Among the three models tested (VGG16, ResNet50, and InceptionV3), the InceptionV3 model yielded the best performance in terms of accuracy (95%). This result suggests that the InceptionV3 architecture is particularly effective for the task of fashion image classification, potentially due to its ability to extract complex features.</div>\n",
    "\n",
    "#### Transfer Learning Effectiveness:\n",
    " <div style=\"text-align: justify\"> Transfer learning with pre-trained models significantly sped up the training process and improved accuracy. The ability to freeze the initial layers and only fine-tune the later layers allowed us to reuse the learned features from large-scale datasets like ImageNet.</div>\n",
    "\n",
    "#### Impact of Data Preprocessing: \n",
    "<div style=\"text-align: justify\"> Normalizing the pixel values and appropriately splitting the dataset into different classes contributed to improving the model’s convergence speed and accuracy. Proper feature engineering and data preprocessing steps are crucial in achieving optimal results in deep learning models.</div>\n",
    "\n",
    "## 7. Suggestions for Next Steps\n",
    "While the current model performs well, there are several areas for improvement:\n",
    "\n",
    "#### Model Fine-tuning:\n",
    "<div style=\"text-align: justify\">  Further fine-tuning the layers of InceptionV3 could result in even higher accuracy. Additionally, exploring different learning rates or the use of dropout layers could improve generalization and prevent overfitting.</div>\n",
    "\n",
    "#### Data Augmentation: \n",
    "<div style=\"text-align: justify\"> Implementing data augmentation techniques (such as rotations, flips, and zooming) could help improve the model’s robustness and generalization by artificially increasing the size of the training dataset.</div>\n",
    "\n",
    "#### Experimenting with More Complex Architectures: \n",
    "<div style=\"text-align: justify\"> While InceptionV3 performed well, other architectures such as DenseNet or EfficientNet might yield even better results. It would be valuable to experiment with these architectures to see if they outperform the current model.</div>\n",
    "\n",
    "#### Exploring Other Domains: \n",
    "<div style=\"text-align: justify\"> The current model was fine-tuned on fashion-related data, but it can be adapted to other domains, such as medical images or satellite images, using a similar approach. Exploring these other domains could open up new applications of transfer learning.</div>\n",
    "\n",
    "## 8. Conclusion\n",
    "<div style=\"text-align: justify\"> In conclusion, transfer learning proved to be an effective technique for fashion image classification. By leveraging pre-trained models, we were able to significantly improve the accuracy of the model while using fewer computational resources. The InceptionV3 model provided the best performance and is recommended for deployment in this use case. Future steps include refining the model through further fine-tuning, data augmentation, and exploring more complex architectures for even better results.</div>\n",
    "\n",
    "<div style=\"text-align: justify\"> This project successfully demonstrates the power of deep learning and transfer learning in real-world applications, offering significant insights into how pretrained models can be adapted to specific tasks efficiently.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71313ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist as mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9840dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe61f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647fb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2cfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a32069",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace1e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\117100631\\Documents\\cursera4\\IBM-Machine-Learning-Professional-Certificate\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db82453",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00382fe",
   "metadata": {},
   "source": [
    "## Data description\n",
    "<div style=\"text-align: justify\"> The dataset contains 60.000 grayscale images of 10 fashion categories, along with a test set of \n",
    "10.000 images. Each image is 28 pixels wide and 28 pixels high. Each category is labeled with a \n",
    "number from 0 to 9. Classes are detailed below:</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64dc00b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, \n",
    "          return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf19ee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, \n",
    "          return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648f49f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[555].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3619e18",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> We clearly notice that we have the same number of observations (6000 for the train set and \n",
    "1000 for the test set) for each of our 10 categories. Also, we can observe the shape of a random \n",
    "image (32x32). Here are some examples of the images and their corresponding label, an ankle \n",
    "boot (9) and a t-shirt (0)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b43e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f78a969cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[66])\n",
    "plt.imshow(x_train[66])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682ba2c",
   "metadata": {},
   "source": [
    "## Model deployment\n",
    "<div style=\"text-align: justify\"> First, we set the main parameters and to simplify \n",
    "things, we write a function to include all the training \n",
    "steps. As input, the function takes a model, training set, \n",
    "test set, and the number of classes. Inside the model \n",
    "object will be the state about which layers we are \n",
    "freezing and which we are training. Then, the data is \n",
    "shuffled and split between train and test sets. Next step \n",
    "is to create two datasets: one including half of the \n",
    "classes (T-shirt/top, Trouser, Pullover, Dress and Coat) \n",
    "and another one including the other half (Sandal, Shirt, Sneaker, Bag and Ankle boot). After that, \n",
    "we define the \"feature\" and “classification” layers. The feature layers are the early layers that \n",
    "we expect will \"transfer\" to a new problem. We will freeze these layers during the fine-tuning \n",
    "process. The classification layers are the later layers that predict the specific classes from the \n",
    "features learned by the feature layers. This is the part of the model that needs to be re-trained \n",
    "for a new problem. Finally, we create out model by combining the two sets of layers. Here is a \n",
    "summary of our model. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb45d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69745b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600,165</span> (2.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m600,165\u001b[0m (2.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600,165</span> (2.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m600,165\u001b[0m (2.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2a0ae",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> Now, we train our model on the second half of the classes (Sandal, Shirt, Sneaker, Bag and Ankle \n",
    "boot). We notice that accuracy tends to go up and probably can continue to improve.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adaed6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.1931 - loss: 1.6116 - val_accuracy: 0.2732 - val_loss: 1.5743\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.2599 - loss: 1.5751 - val_accuracy: 0.4468 - val_loss: 1.5349\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3332 - loss: 1.5414 - val_accuracy: 0.5642 - val_loss: 1.4948\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3993 - loss: 1.5017 - val_accuracy: 0.6622 - val_loss: 1.4512\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4662 - loss: 1.4598 - val_accuracy: 0.7114 - val_loss: 1.4015\n",
      "Training time: 0:00:18.480478\n",
      "Test score: 1.4014841318130493\n",
      "Test accuracy: 0.7113999724388123\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a853d3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> We freeze only the feature layers. A lot of the training time is spent \"back-propagating\" the \n",
    "gradients back to the first layer. Therefore, if we only need to compute the gradients back a \n",
    "small number of layers, the training time is much quicker per iteration. This is in addition to the \n",
    "savings gained by being able to train on a smaller data set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d49e4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f6b503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,497</span> (6.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,800,497\u001b[0m (6.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">590,597</span> (2.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m590,597\u001b[0m (2.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,568</span> (37.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,568\u001b[0m (37.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,200,332</span> (4.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,200,332\u001b[0m (4.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335eaac",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> We can observe above the differences between the number of total params, trainable params, \n",
    "and non-trainable params </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a36c5b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2239 - loss: 1.6754 - val_accuracy: 0.2252 - val_loss: 1.6322\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2572 - loss: 1.6245 - val_accuracy: 0.3860 - val_loss: 1.5738\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3093 - loss: 1.5774 - val_accuracy: 0.4318 - val_loss: 1.5239\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3589 - loss: 1.5319 - val_accuracy: 0.4638 - val_loss: 1.4834\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3917 - loss: 1.4965 - val_accuracy: 0.5364 - val_loss: 1.4478\n",
      "Training time: 0:00:09.980844\n",
      "Test score: 1.4478203058242798\n",
      "Test accuracy: 0.5364000201225281\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250a43e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> Note that even though nearly all (590K/600K) of the parameters were trainable, the training \n",
    "time per epoch was still much reduced. This is because the unfrozen part of the network was \n",
    "very shallow, making backpropagation faster.\n",
    "Now we will make the opposite training process: train on the first half of the classes and finetune \n",
    "only the last layers on the second half of the classes. </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4570ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600,165</span> (2.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m600,165\u001b[0m (2.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600,165</span> (2.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m600,165\u001b[0m (2.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_layers2 = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers2 = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "model2 = Sequential(feature_layers2 + classification_layers2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "520614c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.2164 - loss: 1.6271 - val_accuracy: 0.4016 - val_loss: 1.5690\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3011 - loss: 1.5690 - val_accuracy: 0.4862 - val_loss: 1.5116\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3705 - loss: 1.5191 - val_accuracy: 0.5400 - val_loss: 1.4539\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4181 - loss: 1.4662 - val_accuracy: 0.6314 - val_loss: 1.3929\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4715 - loss: 1.4109 - val_accuracy: 0.6914 - val_loss: 1.3308\n",
      "Training time: 0:00:19.108042\n",
      "Test score: 1.3307768106460571\n",
      "Test accuracy: 0.6913999915122986\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9672b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in feature_layers2:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7629bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,497</span> (6.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,800,497\u001b[0m (6.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">590,597</span> (2.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m590,597\u001b[0m (2.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,568</span> (37.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,568\u001b[0m (37.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,200,332</span> (4.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,200,332\u001b[0m (4.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ee1acbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1814 - loss: 1.6703 - val_accuracy: 0.2382 - val_loss: 1.5873\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2451 - loss: 1.5838 - val_accuracy: 0.3100 - val_loss: 1.5003\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3329 - loss: 1.5080 - val_accuracy: 0.4656 - val_loss: 1.4248\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4270 - loss: 1.4369 - val_accuracy: 0.6634 - val_loss: 1.3563\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5125 - loss: 1.3728 - val_accuracy: 0.7126 - val_loss: 1.2944\n",
      "Training time: 0:00:10.392547\n",
      "Test score: 1.2944233417510986\n",
      "Test accuracy: 0.7125999927520752\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5696a",
   "metadata": {},
   "source": [
    "## Key findings\n",
    "<div style=\"text-align: justify\"> We were able to reduce the training time, despite not having achieved the same accuracy results \n",
    "that we had before. Each epoch is moving a lot faster and getting continuous improvement on \n",
    "accuracy score. This was one of our main objectives and it is significant since we could add extra \n",
    "epochs and get improved accuracy while doing it in less time than just running it from the \n",
    "beginning.</div>\n",
    "\n",
    "## Suggestions for next steps\n",
    "\n",
    "<div style=\"text-align: justify\"> Models should be revisited and consider where to fine tune and how deep to fine tune for \n",
    "achieving better and growing accuracy results. This could be done by trying to hold different \n",
    "parts constant and changing parameters. In addition, the time advantage gained in training time \n",
    "can be exploited.</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
