{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork32585014-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collaborative Filtering based Recommender System using K Nearest Neighbor**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is probably the most commonly used recommendation algorithm, there are two main types of methods:\n",
    "\n",
    "*   **User-based** collaborative filtering is based on the user similarity or neighborhood\n",
    "*   **Item-based** collaborative filtering is based on similarity among items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They both work similarly, let's briefly explain how user-based collaborative filtering works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-based collaborative filtering looks for users who are similar. This is very similar to the user clustering method done previously; where we employed explicit user profiles to calculate user similarity. However, the user profiles may not be available, so how can we determine if two users are similar?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-item interaction matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most collaborative filtering-based recommender systems, the main dataset format is a 2-D matrix called the user-item interaction matrix. In the matrix,  its row is labeled as the user id/index and column labelled to be the item id/index, and the element `(i, j)` represents the rating of user `i` to item `j`.\n",
    "\n",
    "Below is a simple example of a user-item interaction matrix:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module\\_4/images/user_item_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN-based collaborative filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, each row vector represents the rating history of a user and each column vector represents the users who rated the item. A user-item interaction matrix is usually very sparse as you can imagine one user very likely only interacts with a very small subset of items and one item is very likely to be interacted by a small subset of users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to determine if two users are similar, we can simply calculate the similarities between their row vectors in the interaction matrix. Then based on the similarity measurements, we can find the `k` nearest neighbor as the similar users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-based collaborative filtering works similarly, we just need to look at the user-item matrix vertically. Instead of finding similar users, we are trying to find similar items (courses). If two courses are enrolled by two groups of similar users, then we could consider the two items are similar and use the known ratings from the other users to predict the unknown ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we formulate the KNN based collaborative filtering,  the predicted rating of user $u$ to item $i$, $\\hat{r}\\_{ui}$ is given by:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User-based** collaborative filtering:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{r}*{ui} = \\frac{\n",
    "\\sum\\limits*{v \\in N^k_i(u)} \\text{similarity}(u, v) \\cdot r\\_{vi}}\n",
    "{\\sum\\limits\\_{v \\in N^k_i(u)} \\text{similarity}(u, v)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Item-based** collaborative filtering:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{r}*{ui} = \\frac{\n",
    "\\sum\\limits*{j \\in N^k_u(i)} \\text{similarity}(i, j) \\cdot r\\_{uj}}\n",
    "{\\sum\\limits\\_{j \\in N^k_u(i)} \\text{similarity}(i, j)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $N^k_i(u)$ notates the nearest k neighbors of $u$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate how the equation works using a simple example. From the above figure, suppose we want to predict the rating of `user6` to item `Machine Learning Capstone` course. After some similarity measurements, we found that k = 4 nearest neighbors: `user2, user3, user4, user5` with similarities in array `knn_sims`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example similarity array stores the similarity of user2, user3, user4, and user5 to user6\n",
    "knn_sims = np.array([0.8, 0.92, 0.75, 0.83])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also their rating on the `Machine Learning Capstone` course are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 means audit and 3.0 means complete the course\n",
    "knn_ratings = np.array([3.0, 3.0, 2.0, 3.0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the predicted rating of `user6` to item `Machine Learning Capstone` course can be calculated as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7727272727272725"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_u6_ml =  np.dot(knn_sims, knn_ratings)/ sum(knn_sims)\n",
    "r_u6_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already know the true rating to be 3.0, then we get a prediction error RMSE (Rooted Mean Squared Error) as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22727272727272751"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rating = 3.0\n",
    "rmse = math.sqrt(true_rating - r_u6_ml) ** 2\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted rating is around 2.7 (close to 3.0 with RMSE 0.22), which indicates that `user6` is also likely to complete the course `Machine Learning Capstone`. As such, we may recommend it to user6 with high confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Perform KNN-based collaborative filtering on the user-item interaction matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and exploring dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load our dataset, i.e., a user-item (learn-course) interaction matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\n",
    "rating_df = pd.read_csv(rating_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889878</td>\n",
       "      <td>CC0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342067</td>\n",
       "      <td>CL0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990814</td>\n",
       "      <td>ML0120ENv3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380098</td>\n",
       "      <td>BD0211EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>779563</td>\n",
       "      <td>DS0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        item  rating\n",
       "0  1889878    CC0101EN     3.0\n",
       "1  1342067    CL0101EN     3.0\n",
       "2  1990814  ML0120ENv3     3.0\n",
       "3   380098    BD0211EN     3.0\n",
       "4   779563    DS0101EN     3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains three columns, `user id` (learner), `item id`(course), and `rating`(enrollment mode).\n",
    "\n",
    "Note that this matrix is presented as the dense or vertical form, and you may convert it to a sparse matrix using `pivot` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>AI0111EN</th>\n",
       "      <th>BC0101EN</th>\n",
       "      <th>BC0201EN</th>\n",
       "      <th>BC0202EN</th>\n",
       "      <th>BD0101EN</th>\n",
       "      <th>BD0111EN</th>\n",
       "      <th>BD0115EN</th>\n",
       "      <th>BD0121EN</th>\n",
       "      <th>BD0123EN</th>\n",
       "      <th>...</th>\n",
       "      <th>SW0201EN</th>\n",
       "      <th>TA0105</th>\n",
       "      <th>TA0105EN</th>\n",
       "      <th>TA0106EN</th>\n",
       "      <th>TMP0101EN</th>\n",
       "      <th>TMP0105EN</th>\n",
       "      <th>TMP0106</th>\n",
       "      <th>TMP107</th>\n",
       "      <th>WA0101EN</th>\n",
       "      <th>WA0103EN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  AI0111EN  BC0101EN  BC0201EN  BC0202EN  BD0101EN  BD0111EN  BD0115EN  \\\n",
       "0     2       0.0       3.0       0.0       0.0       3.0       2.0       0.0   \n",
       "1     4       0.0       0.0       0.0       0.0       2.0       2.0       2.0   \n",
       "2     5       2.0       2.0       2.0       0.0       2.0       0.0       0.0   \n",
       "3     7       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4     8       0.0       0.0       0.0       0.0       0.0       2.0       0.0   \n",
       "\n",
       "   BD0121EN  BD0123EN  ...  SW0201EN  TA0105  TA0105EN  TA0106EN  TMP0101EN  \\\n",
       "0       2.0       2.0  ...       0.0     2.0       0.0       3.0        0.0   \n",
       "1       2.0       2.0  ...       0.0     2.0       0.0       0.0        0.0   \n",
       "2       0.0       2.0  ...       0.0     0.0       2.0       2.0        2.0   \n",
       "3       0.0       0.0  ...       0.0     0.0       0.0       0.0        0.0   \n",
       "4       0.0       0.0  ...       0.0     0.0       0.0       0.0        0.0   \n",
       "\n",
       "   TMP0105EN  TMP0106  TMP107  WA0101EN  WA0103EN  \n",
       "0        2.0      2.0     0.0       3.0       0.0  \n",
       "1        2.0      2.0     0.0       2.0       2.0  \n",
       "2        2.0      2.0     2.0       0.0       2.0  \n",
       "3        0.0      0.0     0.0       0.0       0.0  \n",
       "4        0.0      0.0     0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_sparse_df = rating_df.pivot(index='user', columns='item', values='rating').fillna(0).reset_index().rename_axis(index=None, columns=None)\n",
    "rating_sparse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the dense format is more preferred as it saves a lot of storage and memory space. While the benefit of the sparse matrix is it is in the nature matrix format and you could apply computations such as cosine similarity directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to perform KNN-based collaborative filtering on the user-item interaction matrix.\n",
    "You may choose one of the two following implementation options of KNN-based collaborative filtering.\n",
    "\n",
    "*   The first one is to use `scikit-surprise` which is a popular and easy-to-use Python recommendation system library.\n",
    "*   The second way is to implement it with standard `numpy`, `pandas`, and `sklearn`. You may need to write a lot of low-level implementation code along the way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Option 1: Use **Surprise** library (recommended)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Surprise* is a Python sci-kit library for recommender systems. It is simple and comprehensive to build and test different recommendation algorithms.\n",
    "\n",
    "First, let's install it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise==1.1.1\n",
      "  Using cached scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\117100631\\documents\\cursera4\\ibm-machine-learning-professional-certificate\\.venv\\lib\\site-packages (from scikit-surprise==1.1.1) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\117100631\\documents\\cursera4\\ibm-machine-learning-professional-certificate\\.venv\\lib\\site-packages (from scikit-surprise==1.1.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\117100631\\documents\\cursera4\\ibm-machine-learning-professional-certificate\\.venv\\lib\\site-packages (from scikit-surprise==1.1.1) (1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\117100631\\documents\\cursera4\\ibm-machine-learning-professional-certificate\\.venv\\lib\\site-packages (from scikit-surprise==1.1.1) (1.17.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [143 lines of output]\n",
      "      C:\\Users\\117100631\\AppData\\Local\\Temp\\pip-install-iu_1cccm\\scikit-surprise_833b34053c154a1eb1bfd628e2a35044\\setup.py:45: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.Distribution().fetch_build_eggs(['numpy>=1.11.2'])\n",
      "      C:\\Users\\117100631\\Documents\\cursera4\\IBM-Machine-Learning-Professional-Certificate\\.venv\\Lib\\site-packages\\setuptools\\dist.py:599: SetuptoolsDeprecationWarning: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "      \n",
      "              By 2026-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self._enforce_underscore(opt, section)\n",
      "      C:\\Users\\117100631\\Documents\\cursera4\\IBM-Machine-Learning-Professional-Certificate\\.venv\\Lib\\site-packages\\setuptools\\dist.py:599: SetuptoolsDeprecationWarning: Invalid dash-separated key 'description-file' in 'metadata' (setup.cfg), please use the underscore name 'description_file' instead.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "              (Affected: scikit-surprise).\n",
      "      \n",
      "              By 2026-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self._enforce_underscore(opt, section)\n",
      "      C:\\Users\\117100631\\Documents\\cursera4\\IBM-Machine-Learning-Professional-Certificate\\.venv\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\dump.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\reader.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\utils.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      creating build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "      creating build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      running egg_info\n",
      "      writing scikit_surprise.egg-info\\PKG-INFO\n",
      "      writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "      writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "      writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "      writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "      reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      adding license file 'LICENSE.md'\n",
      "      writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\117100631\\Documents\\cursera4\\IBM-Machine-Learning-Professional-Certificate\\.venv\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'surprise.prediction_algorithms' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'surprise.prediction_algorithms' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'surprise.prediction_algorithms' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'surprise.prediction_algorithms' to be distributed and are\n",
      "              already explicitly excluding 'surprise.prediction_algorithms' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "      running build_ext\n",
      "      building 'surprise.similarities' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (scikit-surprise)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise==1.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import required classes and methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNNBasic\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise.trainset.Trainset"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k', prompt=False)\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "type(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's take a look at a code example how easily to perform KNN collaborative filtering on a sample movie review dataset, which contains about 100k movie ratings from users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9832791953336634"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = Dataset.load_builtin('ml-100k', prompt=False)\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# We'll use the famous KNNBasic algorithm.\n",
    "algo = KNNBasic()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, just a couple of lines and you can apply KNN collaborative filtering on the sample movie lens dataset. The main evaluation metric is `Root Mean Square Error (RMSE)` which is a very popular rating estimation error metric used in recommender systems as well as many regression model evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our own course rating dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.to_csv(\"course_ratings.csv\", index=False)\n",
    "# Read the course rating dataset with columns user item rating\n",
    "reader = Reader(\n",
    "        line_format='user item rating', sep=',', skip_lines=1, rating_scale=(2, 3))\n",
    "\n",
    "coruse_dataset = Dataset.load_from_file(\"course_ratings.csv\", reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split it into trainset and testset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(coruse_dataset, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then check how many users and items we can use to fit a KNN model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 31335 users and 123 items in the trainingset\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total {trainset.n_users} users and {trainset.n_items} items in the trainingset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Perform KNN-based collaborative filtering on the user-item interaction matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Fit the KNN-based collaborative filtering model using the trainset and evaluate the results using the testset:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.2063\n",
      "RMSE: 0.20626601933358374\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE:\n",
    "\n",
    "\n",
    "# - Define a KNNBasic() model\n",
    "# Note there are some arguments such as:\n",
    "# max_k and min_k, representing the max and min number of neighors for rating estimations\n",
    "# sim_option, representing similarity measurement such as cosine and whether you want it to be user_based or items_based \n",
    "# e.g., sim_option = {\n",
    "#        'name': 'cosine', 'user_based': False,\n",
    "#    }\n",
    "#\n",
    "# more KNN model hyperparamets can be found here:\n",
    "# https://surprise.readthedocs.io/en/stable/knn_inspired.html\n",
    "# \n",
    "# You may try different hyperparamet combinations to see which one has the best performance\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # compute  similarities between items\n",
    "}\n",
    "model = KNNBasic(min_k=5,max_k=100,sim_options=sim_options)\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print('RMSE:',rmse)\n",
    "# - Train the KNNBasic model on the trainset, and predict ratings for the testset\n",
    "\n",
    "# - Then compute RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more detailed usages about *Surprise* library, visit its website from [here](https://surprise.readthedocs.io/en/stable/getting_started.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork32585014-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you have learned and implemented KNN-based collaborative filtering. It is probably the simplest but very effective and intuitive collaborative filtering algorithm. Since it is based on KNN, it inherits the main characteristics of KNN such as memory-intensive because you need to maintain a huge similarity matrix among users or items. In the future labs, we will learn other types of collaborative filtering which do not rely on such a huge similarity matrix to make rating predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork32585014-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description          |\n",
    "| ----------------- | ------- | ---------- | --------------------------- |\n",
    "| 2021-10-25        | 1.0     | Yan        | Created the initial version |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
